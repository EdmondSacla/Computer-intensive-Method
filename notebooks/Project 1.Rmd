---
title: "Computer Intensive Methods: Final projects (2024/2025), Project 1"
output: pdf_document
date: "`r format(Sys.time(), '%d %B, %Y')`"
author: "Mikita Bisliuk, Edmond Sacla Aide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)

library(foreach)
library(doParallel)

n_cores <- detectCores()
cluster <- makeCluster(n_cores - 1L)
registerDoParallel(cluster)

GLOBAL_B <- 1000L
```

# Project 1

In this project, in all questions, we focused on the nassCDS data which is a US data from police-reported car crashes (1997-2002) in which there is a harmful event (people or property). Data are restricted to front-seat occupants, include only a subset of the variables recorded. More information about the dataset can be found using the following link: https://www.rdocumentation.org/packages/DAAG/versions/1.22/topics/nassCDS. The data is a part of the DAAG R package. To get an access to the data you first need to install the package. The list of variables names is shown below.

```{r, echo=TRUE}
library("DAAG")
library("robust")

data(nassCDS)
nassCDS <- na.omit(nassCDS) #  complete cases analysis
names(nassCDS)
```

```{r, echo=TRUE}
dim(nassCDS)
```

## Part 1

Let $Y_i$ be an indicator variable which takes the value of 1 if an occupant died in an accident (the variable *dead*) and zero otherwise and $X_i$ be the age of occupant in years (the variable *ageOFocc*). We consider the following GLM:

$g(P(Y_i = 1)) = \beta_0 + \beta_1 X_i$

### Question 1.1

Estimate the model using a classical GLM approach

```{r}
glm.daag <- glm(dead ~ ageOFocc, data = nassCDS, family = "binomial")
summary(glm.daag)
```

The coefficient estimate for `ageOFocc` is 0.021183. This means that for each additional year of age, the log-odds of the outcome (`dead`) increase by 0.021183 or alternatively the odds to die in a car accident increase by approximately 2.14%. The p-value for `ageOFocc` is less than 2e-16, indicating that the effect of age on the outcome is significant at 5% level of significance.

### Question 1.2

Let $X_{50}$ be the age of occupant for which the probability to die is 0.5, i.e., $P(Y_i = 1) = 0.5$. Estimate $X_{50}$. Use non parametric bootstrap to estimate the distribution of $X_{50}$ and to construct a 95% C.I. for the $X_{50}$

When plug-in $P(Y_i = 1) = 0.5$ to the model equation we obtain:

$$

logit(\pi_i) = log(\frac{\pi_i}{1-\pi_i}) = \beta_0 + \beta_1 x_i \\

\pi_i = 0.5: 0 = \beta_0 + \beta_1 X_{50} \\

X_{50} = -\frac{\beta_0}{\beta_1} \\

$$

```{r}
beta_0 <- coef(glm.daag)[1]
beta_1 <- coef(glm.daag)[2]
sprintf("Median effective level: %.2f", -beta_0 / beta_1)
```

Using a non-parametric bootstrap, the resampling is done directly from the observed data without making any assumptions about the underlying distribution. On each iteration we fit the model to the resampled dataset, extract the coefficient estimates and calculate the median effective level.

```{r, cache=TRUE}
mel.boot <- foreach(i=1:GLOBAL_B, .combine = rbind, .export = c("nassCDS")) %dopar% {
  set.seed(i)
  n <- nrow(nassCDS)
  idx <- sample(n, replace = TRUE)
  model <- glm(dead ~ ageOFocc, data = nassCDS[idx, ], family = binomial(link = "logit"))
  -coef(model)[1] / coef(model)[2]
}
```

The histogram illustrates the distribution of $X_{50}$, 95% confidence interval, observed and estimated via bootstrap median effective levels. The estimated bootstrap value for $X_{50}$ is 185.74 which is very close to the observed value of 184.49. To find 95% CI we calculate 2.5% and 97.5% quantiles from bootstrap results giving [166.82, 209.25].

```{r}
hist(mel.boot, probability = TRUE, nclass = 50, main = "Histogram of median effective level X50")
 
abline(v = quantile(mel.boot, probs = c(0.025, 0.975)), col = "blue", lty = "dashed")
abline(v = mean(mel.boot), col = "blue")
abline(v = -beta_0 / beta_1, col = "red")
```

### Question 1.3

For the model formulated above, estimate the OR (for a unit increased in age). Use non parametric bootstrap to construct a 95% C.I. for the OR (for a unit increased in age) using the percentile and bootstrap *t* interval methods, which one do you prefer for the parameter OR ?

$$
logit(\pi_i) = log(\frac{\pi_i}{1-\pi_i}) = \beta_0 + \beta_1 x_i \\

odds_i = \frac{\pi_i}{1-\pi_i} = exp(\beta_0 + \beta_1 x_i)
$$

```{r}
exp(coef(glm.daag)[2])
```

Repeating procedure from Q 1.2 but this time extracting model summary for $\beta_1$.

```{r, cache=TRUE}
coef.boot <- foreach(i=1:GLOBAL_B, .combine = rbind, .export = c("nassCDS")) %dopar% {
  set.seed(i)
  n <- nrow(nassCDS)
  idx <- sample(n, replace = TRUE)
  model <- glm(dead ~ ageOFocc, data = nassCDS[idx, ], family = binomial(link = "logit"))
  summary(model)$coef["ageOFocc", ]
}
```

To construct 95% percentile CI we take 2.5% and 97.5% percentiles from bootstrap estimates of $\beta_1$ followed by exp() to convert logOR to OR resulting in [1.018282, 1.024623]. The t-statistic is calculated as the difference between the bootstrap estimate and the observed estimate, divided by the bootstrap standard error. The t-interval is constructed by adding the product of the standard error and the t-statistic 2.5% and 97.5% percentiles to the observed $\beta_1$ followed by exp() leading to 1.018319, 1.024627].

Percentile intervals are preferable since `Studentized intervals` do not respect transformation of the form $\phi = m(\theta)$.

```{r}
beta_1 <- coef(glm.daag)[2]
beta_1_se <- summary(glm.daag)$coef["ageOFocc", "Std. Error"]

t.boot <- (coef.boot[,"Estimate"] - beta_1) / coef.boot[,"Std. Error"]
up <- quantile(t.boot, probs = c(0.975))
lo <- quantile(t.boot, probs = c(0.025))

print("95% C.I. using bootstrap t-interval method:")
print(unname(exp(c(beta_1 + beta_1_se * lo, beta_1 + beta_1_se * up))))

print("95% C.I. using bootstrap percentile method:")
print(unname(quantile(exp(coef.boot[,"Estimate"]), probs = c(0.025, 0.975))))
```

### Question 1.4

We focus on the odds ratio (OR) for a unit increased in age. Use parametric bootstrap to test the null hypothesis $H_0: OR = 1$.

```{r}
glm.daag0 <- glm(dead ~ 1, data = nassCDS, family = binomial(link = "logit"))
summary(glm.daag0)
```

```{r}
inv.logit <- function(x) {
  exp(x) / (1 + exp(x))
}
prob <- inv.logit(-3.05484)
prob
```

```{r, cache=TRUE}
attach(nassCDS)

N <- 1000L
t.boot <- coef.boot <- matrix(nrow = N, ncol = 2)
size <- nrow(nassCDS)
for (i in seq_len(N)) {
  dead.boot <- rbinom(size, 1, prob)
  model <- glm(dead.boot ~ ageOFocc, family = binomial(link = "logit"))
  coef.boot[i, ] <- coef(model)
  t.boot[i, ] <- summary(model)$coefficients[, 3]
}
```

```{r}
hist(coef.boot[, 2], nclass = 50, xlim = c(-0.03, 0.03))
abline(v = beta_1, col = "red")
```

### Question 1.5

Let $\pi_{33}$ be the probability of death for an occupant at age 33. Use parametric bootstrap to calculate the standard error for $\pi_{33}$ and construct a 90% C.I. for $\pi_{33}$.

```{r, cache=TRUE}
attach(nassCDS)
size <- nrow(nassCDS)
B <- 1000L
newdata <- data.frame(ageOFocc = 33.0)
pi33.boot <- numeric(N)
for (i in 1:B) {
  dead.boot <- rbinom(size, 1, predict(glm.daag, type = "response"))
  model <- glm(dead.boot ~ ageOFocc, family = binomial(link = "logit"))
  summary(model)
  pi33.boot[i] <- predict(model, newdata = newdata, type = "response")
}

mean(pi33.boot)
var(pi33.boot)
quantile(pi33.boot,probs=c(0.05,0.950))

```

```{r}
hist(pi33.boot,nclass=50)
abline(v = quantile(pi33.boot,probs=c(0.05,0.950)), col = "blue")
```

## Part 2

In this question we fit a robust GLM for the model specified in Q1. Use the R package *glmRob* to fit the model.

### Question 2.1

Estimate the model using the R package glmRob.

```{r}
glm.rob.daag <- glmRob(dead ~ ageOFocc, data = nassCDS, family = "binomial")
summary(glm.rob.daag)
```

### Question 2.2

Use non parametric bootstrap to estimate the SE for the intercept and slope.

```{r, cache=TRUE}
N <- 100L
rob.coef.boot <- matrix(nrow = N, ncol = 2)
size <- nrow(nassCDS)
for (i in seq_len(N)) {
  idx <- sample(size, replace = TRUE)
  model <- glmRob(dead ~ ageOFocc, data = nassCDS[idx,], family = "binomial")
  rob.coef.boot[i, ] <- coef(model)
}
```


```{r}
par(mfrow=c(1,2))
hist(rob.coef.boot[,1],main="alpha",nclass=25)
abline(v = quantile(rob.coef.boot[,1], probs = c(0.025, 0.975)), col = "blue")

hist(rob.coef.boot[,2],main="beta",nclass=25)
abline(v = quantile(rob.coef.boot[,2], probs = c(0.025, 0.975)), col = "blue")
```

### Question 2.3

Use the jackknife and the bootstrap procedures to estimate the bias and MSE for the intercept and slope estimated by: (1) the GLM model in Q2.1 and (2) the robust GLM model estimated in Q2.2. Which method you prefer to use for the estimation of the intercept and slope?

TODO

```{r}
size <- nrow(nassCDS)
rob.coef.jack <- coef.jack <- matrix(nrow = size, ncol = 2)
for (i in 1:size) {
  nassCDS_jack <- nassCDS[-i,]
  glm_model <- glm(dead ~ ageOFocc, data = nassCDS_jack, family = "binomial")
  coef.jack[i, ] <- coef(glm_model)
  
  rob_model <- glmRob(dead ~ ageOFocc, data = nassCDS_jack, family = "binomial")
  rob.coef.jack[i, ] <- coef(rob_model)
}
```

```{r}
mean(coef.boot[,1]) - coef(glm.daag)[1]
(size - 1) * ( mean(coef.jack[, 1]) - coef(glm.daag)[1] )
```

```{r}
mean(coef.boot[,2]) - coef(glm.daag)[2]
(size - 1) * ( mean(coef.jack[, 2]) - coef(glm.daag)[2] )
```

```{r}
mean(rob.coef.boot[,1]) - coef(glm.daag)[1]
(size - 1) * ( mean(rob.coef.jack[, 1]) - coef(glm.daag)[1] )
```

```{r}
mean(rob.coef.boot[,2]) - coef(glm.daag)[2]
(size - 1) * ( mean(rob.coef.jack[, 2]) - coef(glm.daag)[2] )
```

## Part 3

In this question we focus of the following 2 × 2 table (for the complete case analysis) for the variables airbag and dead

```
##
## alive dead
## none 11058 669
## airbag 13825 511
```

### Question 3.1

Define the observation unit ($X_i$, $Y_i$) for the question

```{r}
bag.dead <- matrix(c(11058, 13825, 669, 511), nrow = 2, 
                dimnames = list(c("none", "airbag"), c("alive", "dead")))

addmargins(bag.dead)
```

### Question 3.2

Calculate the odds ratio for usage of airbag and the accident outcome (dead/alive) and construct 95% confidence interval. You can use the R function oddsratio. What is your conclusions? Do you think that airbags in the car influence the accident outcome ?

```{r}
epitools::oddsratio(bag.dead)
```
TODO: interpretation

### Question 3.3

Use parametric bootstrap to construct a construct a 95% confidence interval for the OR.

```{r, cache=TRUE}
B <- 100L
n.nobag <- 669 + 11058
n.airbag <- 511 + 13825
p.nobag <- 669 / n.nobag
p.airbag <- 511 / n.airbag
ors.b <- numeric(B)
for (i in seq_len(B)) {
  s1 <- sum(rbinom(n.nobag, 1, p.nobag))
  s2 <- sum(rbinom(n.airbag, 1, p.airbag))
  ors.b[i] <- epitools::oddsratio(c(n.nobag - s1, s1, n.airbag - s2, s2))$measure[2,1]
}

mean(ors.b)
quantile(ors.b, probs = c(0.025, 0.975))
```

```{r}
hist(ors.b, nclass = 50)
abline(v = quantile(ors.b, probs = c(0.025, 0.975)), col = "red")
```

### Question 3.4

Use permutations test to test the hypothesis that airbags in the car DO NOT influence the accident outcome using a chi-square test for a 2 × 2 table. Compare the distribution of the chi-square test statistic in this question to the theoretical distribution of the test statistic.

```{r}
chisq.test(bag.dead, correct = FALSE)
```

```{r, cache=TRUE}
B <- 1000L
n.nobag <- 669 + 11058
n.airbag <- 511 + 13825
p.pooled <- (669 + 511) / (n.nobag + n.airbag)
chisq.b <- numeric(B)
for (i in seq_len(B)) {
  s1 <- sum(rbinom(n.nobag, 1, p.pooled))
  s2 <- sum(rbinom(n.airbag, 1, p.pooled))
  tbl.b <- matrix(c(n.nobag - s1, s1, n.airbag - s2, s2), byrow = TRUE, nrow = 2)
  chisq.b[i] <- chisq.test(tbl.b)$statistic
}

```

```{r}
hist(chisq.b, breaks = 100, probability = TRUE)
# abline(v = 68.362, col = "red")
curve(dchisq(x, df = 1), col = "red", lwd = 2, add = TRUE)
```

## Part 4

If this question we focus on the variables dead (the outcome of the accident) and the gender (the variable sex).

### Question 4.1

Estimate the proportion of male (𝜋𝑀) and female (𝜋𝐹) that died in the accidents.

```{r}
sex.died <- with(nassCDS, table(sex, dead))
n.total <- sum(sex.died)
n.male <- 716 + 13253
n.female <- 464 + 11784
p.male <- 716 / n.male
p.female <- 464 / n.female
addmargins(sex.died)
```

### Question 4.2

Test the hypothesis that the proportion of male and female that died in an accident are equal using a classical two-samples test (use a two sided test).

```{r}
prop.test(sex.died, correct = FALSE)
```

### Question 4.3

Use parametric bootstrap to test the hypothesis that the proportion of male and female that died in an accidents are equal against a two sided alternative.

```{r}
p.pooled <- (464 + 716) / n.total

B <- 1000L
z.b <- diff.b <- numeric(B)
for (i in 1:B) {
  s1 <- sum(rbinom(n.female, 1, p.pooled))
  p.female.b <- s1 / n.female
  
  s2 <- sum(rbinom(n.male, 1, p.pooled))
  p.male.b <- s2 / n.male
  
  p.total.b <- (s1 + s2) / (n.male + n.female)
  
  diff.b[i] <- p.male.b - p.female.b
  
  z.b[i] <- (p.male.b - p.female.b) / sqrt(p.total.b * (1 - p.total.b) * (1/n.female + 1/n.male))
}
```

```{r}
hist(z.b, nclass=50, probability=TRUE)
```

### Question 4.4

Use non-parametric bootstrap construct a 95% confident interval for 𝜋𝑀 − 𝜋𝐹

```{r}
B <- 1000L
size <- nrow(nassCDS)
diff.b <- numeric(B)
for (i in 1:B) {
  idx.b <- sample(size, replace = TRUE)
  summary.b <- with(nassCDS[idx.b, ], table(dead, sex))
  diff.b[i] <- diff(summary.b[1,] / colSums(summary.b))
}

mean(diff.b)
quantile(diff.b, probs = c(0.025, 0.975))
```

```{r}
hist(diff.b, nclass = 50)
abline(v = quantile(diff.b, probs = c(0.025, 0.975)), col = "red", lty = "dashed")
```


```{r}
stopCluster(cluster)
```
